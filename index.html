<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Praveen Kanithi</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
</head>

<body>
    <div class="container">
        <header class="header">
            <h1 class="name">Praveenkumar Kanithi</h1>
            <p class="title">Machine Learning Researcher</p>
        </header>

        <nav class="navigation">
            <button class="hamburger" id="hamburger">
                <span class="hamburger-line"></span>
                <span class="hamburger-line"></span>
                <span class="hamburger-line"></span>
            </button>
            <ul class="nav-tabs" id="nav-tabs">
                <li><a href="#about" class="nav-link">About</a></li>
                <li><a href="#projects" class="nav-link">Projects</a></li>
                <li><a href="#education" class="nav-link">Education</a></li>
                <li><a href="#publications" class="nav-link">Publications</a></li>
            </ul>
        </nav>

        <main>
            <section id="about" class="section">
                <h2>About</h2>
                <div class="about-content">
                    <div class="about-text">
                        <p>Hi, Iâ€™m Praveen, a Principal Scientist at M42 in Abu Dhabi.
                            I work on machine learning for healthcare, across areas like clinical
                            language models, genomics, electronic health records, and medical imaging.
                            My day-to-day mostly involves figuring out how to make models a bit more
                            useful, reliable, and helpful in real-world clinical settings.</p>
                        <p>I did my PhD at the HITLab in New Zealand, and masters from IIT Kharagpur. Outside of work, I
                            enjoy hiking,
                            traveling, and training Brazilian Jiu-Jitsu.</p>
                    </div>
                    <div class="profile-picture">
                        <img src="figures/praveen.jpeg" alt="Praveenkumar Kanithi" class="profile-img">
                    </div>
                </div>

                <div class="contact-links">
                    <a href="mailto:kanithi.praveenkumar7@gmail.com" class="contact-link">
                        <span class="contact-icon">ðŸ“§</span> Email
                    </a>
                    <a href="https://github.com/praveenkanithi" target="_blank" class="contact-link">
                        <svg class="contact-icon" width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
                            <path
                                d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z" />
                        </svg>
                        GitHub
                    </a>
                    <a href="https://scholar.google.com/citations?user=UFf9NzMAAAAJ&hl=en" target="_blank"
                        class="contact-link">
                        <svg class="contact-icon" width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
                            <path
                                d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z" />
                        </svg>
                        Google Scholar
                    </a>
                    <a href="https://linkedin.com/in/praveen74" target="_blank" class="contact-link">
                        <svg class="contact-icon" width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
                            <path
                                d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z" />
                        </svg>
                        LinkedIn
                    </a>
                    <a href="https://huggingface.co/pkanithi" target="_blank" class="contact-link">
                        <span class="contact-icon">ðŸ¤—</span> Hugging Face
                    </a>
                </div>
            </section>

            <section id="projects" class="section">
                <h2>Projects</h2>
                <div class="project">
                    <h3>BioToken & BioFM: Biologically-Informed Genomic Foundation Modeling</h3>
                    <p class="project-description">A modular tokenization framework and foundation model that
                        integrate biological structure and function directly into genomic representations. This approach
                        enhances generalization across molecular phenotypes and achieves state-of-the-art performance on
                        diverse genomic prediction tasks with substantially reduced computational cost, demonstrating
                        the power of biologically informed inductive biases in large-scale genomics.</p>
                    <div class="project-image">
                        <img src="figures/biotoken_biofm.png" alt="Project 1 Screenshot" class="project-img">
                    </div>
                    <div class="project-links">
                        <a href="https://www.biorxiv.org/content/10.1101/2025.03.27.645711v1" target="_blank">Paper</a>
                        <a href="https://github.com/m42-health/biofm-eval/" target="_blank">Code</a>
                        <a href="https://huggingface.co/m42-health/BioFM-265M" target="_blank">Model</a>
                    </div>
                </div>

                <div class="project">
                    <h3>MEDIC: Multidimensional Evaluation of Clinical LLMs</h3>
                    <p class="project-description">A framework for evaluating large language models in
                        healthcare across reasoning, ethics, safety, and language understanding. MEDIC introduces a
                        novel cross-examination approach for assessing performance and hallucination without reference
                        outputs, supporting informed model selection for diverse clinical applications.</p>
                    <div class="project-image">
                        <img src="figures/MEDIC_framework.png" alt="Project 2 Screenshot" class="project-img">
                    </div>
                    <div class="project-links">
                        <!-- <a href="https://github.com/yourusername/project2" target="_blank">Code</a> -->
                        <a href="https://arxiv.org/abs/2409.07314" target="_blank">Paper</a>
                        <a href="https://huggingface.co/spaces/m42-health/MEDIC-Benchmark" target="_blank">Demo</a>
                    </div>
                </div>

                <div class="project">
                    <h3>Med42: Open Medical Language Models</h3>
                    <p class="project-description">An effort to build and refine open medical language
                        models through clinical domain adaptation and alignment. The Med42 series explores ways to
                        improve clinical reasoning, factual accuracy, and safety across a range of medical tasks,
                        contributing open and reproducible resources for the research community.</p>
                    <div class="project-image">
                        <img src="figures/med42.png" alt="Project 3 Screenshot" class="project-img">
                    </div>
                    <div class="project-links">
                        <!-- <a href="https://github.com/yourusername/project3" target="_blank">Code</a> -->
                        <a href="https://arxiv.org/pdf/2408.06142" target="_blank">Paper</a>
                        <a href="https://huggingface.co/m42-health/Llama3-Med42-70B" target="_blank">Model</a>
                    </div>
                </div>

                <div class="project">
                    <h3>CXformer: Efficient Scaling of Vision Transformers for Chest X-ray Analysis</h3>
                    <p class="project-description">A study adapting vision transformer architectures
                        for clinical imaging. CXformer builds on DINOv2 through targeted architectural and training
                        refinements, improving efficiency and performance on major chest X-ray benchmarks. The model
                        demonstrates that training optimizations can outweigh scaling, achieving competitive results
                        across classification, segmentation, and report generation tasks.</p>
                    <div class="project-image">
                        <img src="figures/CXformer.png" alt="Project 3 Screenshot" class="project-img">
                    </div>
                    <div class="project-links">
                        <!-- <a href="https://github.com/yourusername/project3" target="_blank">Code</a> -->
                        <a href="https://openreview.net/pdf?id=6fqfInxqG1" target="_blank">Paper</a>
                        <a href="https://github.com/m42-health/CXformer/" target="_blank">Code</a>
                        <a href="https://huggingface.co/m42-health/CXformer-base" target="_blank">Model</a>
                    </div>
                </div>
            </section>

            <section id="education" class="section">
                <h2>Education</h2>
                <div class="education-item">
                    <h3>Ph.D.</h3>
                    <p class="institution">HITLab, University of Canterbury</p>
                    <p class="year">03/2017 â€“ 05/2020</p>
                    <p class="thesis">Thesis: Interactive image segmentation of MARS spectral CT datasets</p>
                    <p class="thesis-description">This thesis addressed the challenge of segmenting spectral CT images
                        for pre-clinical studies, where limited datasets and variable imaging conditions make automatic
                        methods
                        unreliable. An interactive segmentation framework was developed, beginning with a
                        bag-of-features
                        approach for 2D images and later extended to incorporate spatial user cues and 2-stage
                        conditional
                        random fields to improve segmentation accuracy at boundaries. The work was further adapted to
                        volumes
                        through a slice-wise strategy, enabling user interactions to propagate consistently across
                        slices.
                        These methods were implemented as software tools to support researchers and clinicians.</p>
                </div>

                <div class="education-item">
                    <h3>M.Tech. in Medical imaging and informatics</h3>
                    <p class="institution">IIT Kharagpur</p>
                    <p class="year">07/2014 - 05/2016</p>
                    <p class="thesis">Thesis: Immersive augmented reality system for assiting needle positioning during
                        ultrasound guided intervention</p>
                    <p class="thesis-description">This thesis developed an augmented reality system to support
                        ultrasound-guided needle interventions, where accurate in-plane alignment of the needle with the
                        ultrasound probe is often difficult. The system tracked both the probe and needle in a 3D world
                        coordinate system using fiducial markers, enabling real-time visualization of the projected
                        needle trajectory on the ultrasound image before insertion. The approach aimed to reduce the
                        need for multiple punctures during free-hand procedures and to improve clinician navigation. The
                        visualization was further integrated into a head-mounted display, providing an immersive AR
                        interface that overlaid navigation assistance directly on the live ultrasound feed.</p>
                </div>

                <div class="education-item">
                    <h3>B.Tech. in Electronics and communication engineering</h3>
                    <p class="institution">RGUKT Basar</p>
                    <p class="year">07/2010 - 05/2014</p>
                </div>
            </section>

            <section id="publications" class="section">
                <h2>Publications</h2>
                <p class="publications-note">A full list of publications can be found on <a
                        href="https://scholar.google.com/citations?user=UFf9NzMAAAAJ&hl=en" target="_blank">Google
                        Scholar</a>. * indicates equal contribution.</p>

                <div class="publication">
                    <p class="publication-text">Maslenkova, S., Christophe, C., Pimentel, M. A., ... <b>Kanithi,
                            P.</b> Building Trust in Clinical Analysis: Bias Analysis and Dataset Transparency.
                        <em>EMNLP 2025
                            (Accepted)</em>. <a href="#" target="_blank">PDF</a> | <a href="#"
                            target="_blank">Dataset</a>
                    </p>
                </div>

                <div class="publication">
                    <p class="publication-text">Medvedev, A.*, Viswanathan, K.*, <b>Kanithi, P.*</b>, Vishniakov, K.,
                        Munjal, P., Christophe, C., ... & Khan, S. (2025). BioToken and BioFM-Biologically-Informed
                        Tokenization Enables Accurate and Efficient Genomic Foundation Models. bioRxiv, 2025-03. <a
                            href="https://huggingface.co/m42-health/BioFM-265M" target="_blank">PDF</a> | <a
                            href="https://github.com/m42-health/biofm-eval/" target="_blank">Code</a> | <a
                            href="https://huggingface.co/m42-health/BioFM-265M" target="_blank">Model</a></p>
                </div>

                <div class="publication">
                    <p class="publication-text">Al-Mahrooqi, A., Munjal, P., Rajan, R., Pimentel, M. A.,
                        <b>Kanithi, P.</b> (2025). <em>Empirical Analysis of Scaling Vision Foundation Models for Chest
                            X-rays. In Medical Imaging with Deep Learning</em>. <a
                            href="https://openreview.net/pdf?id=6fqfInxqG1" target="_blank">PDF</a> | <a
                            href="https://huggingface.co/m42-health/CXformer-base" target="_blank">Model</a>
                    </p>
                </div>

                <div class="publication">
                    <p class="publication-text"><b>Kanithi, P. K.</b>, Christophe, C., Pimentel, M. A., Raha, T., Saadi,
                        N., Javed, H., ... & Khan, S. (2024). MEDIC: Towards a Comprehensive Framework for Evaluating
                        LLMs in Clinical Applications. arXiv preprint arXiv:2409.07314. <em>(Presented at NVIDIA GTC
                            2025)</em> <a href="https://arxiv.org/abs/2409.07314" target="_blank">PDF</a> | <a
                            href="https://huggingface.co/spaces/m42-health/MEDIC-Benchmark" target="_blank">Demo</a></p>
                </div>

                <div class="publication">
                    <p class="publication-text">Christophe, C., Raha, T., Maslenkova, S., Salman, M. U., <b>Kanithi,
                            P.</b>,
                        Pimentel, M., & Khan, S. (2024, November). Beyond Fine-tuning: Unleashing the Potential of
                        Continuous Pretraining for Clinical LLMs. <em>In Findings of the Association for Computational
                            Linguistics: EMNLP 2024 (pp. 10549-10561).</em> <a
                            href="https://aclanthology.org/2024.findings-emnlp.618/" target="_blank">PDF</a></p>
                </div>

                <div class="publication">
                    <p class="publication-text">Christophe, C., <b>Kanithi, P. K.</b>, Munjal, P., Raha, T., Hayat, N.,
                        Rajan, R., ... & Khan, S. (2024). Med42--Evaluating Fine-Tuning Strategies for Medical LLMs:
                        Full-Parameter vs. Parameter-Efficient Approaches. <em>AAAI Clinical LLM
                            symposium.</em> <a href="https://arxiv.org/abs/2404.14779" target="_blank">PDF</a> | <a
                            href="https://huggingface.co/spaces/m42-health/med42-70b" target="_blank">Model</a></p>
                </div>

                <div class="publication">
                    <p class="publication-text"><b>Kanithi, P.</b>, De Ruiter, N. J., Amma, M. R., Lindeman, R. W.,
                        Butler, A.
                        P., Butler, P. H., ... & Younger, W. R. (2020). <em>Interactive image segmentation of MARS
                            datasets
                            using bag of features. IEEE transactions on radiation and plasma medical sciences, 5(4),
                            559-567</em>. <a href="https://ieeexplore.ieee.org/document/9225700/"
                            target="_blank">PDF</a></p>
                </div>

                <div class="publication">
                    <p class="publication-text"><b>Kanithi, P. K.</b>, Chatterjee, J., & Sheet, D. (2016, December).
                        Immersive
                        augmented reality system for assisting needle positioning during ultrasound guided intervention.
                        <em>In Proceedings of the Tenth Indian Conference on Computer Vision, Graphics and Image
                            Processing (pp. 1-8)</em>. <a href="https://dl.acm.org/doi/abs/10.1145/3009977.3010023"
                            target="_blank">PDF</a>
                    </p>
                </div>
            </section>
        </main>

        <footer class="footer">
            <p>&copy; 2025 Praveenkumar Kanithi. All rights reserved.</p>
        </footer>
    </div>

    <script>
        // Hamburger menu toggle
        const hamburger = document.getElementById('hamburger');
        const navTabs = document.getElementById('nav-tabs');

        hamburger.addEventListener('click', function () {
            navTabs.classList.toggle('nav-open');
            hamburger.classList.toggle('hamburger-open');
        });

        // Close mobile menu when clicking on a link
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', function () {
                navTabs.classList.remove('nav-open');
                hamburger.classList.remove('hamburger-open');
            });
        });

        // Smooth scrolling for navigation links
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', function (e) {
                e.preventDefault();
                const targetId = this.getAttribute('href');
                const targetSection = document.querySelector(targetId);

                if (targetSection) {
                    targetSection.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });

        // Highlight active navigation link based on scroll position
        window.addEventListener('scroll', function () {
            const sections = document.querySelectorAll('.section');
            const navLinks = document.querySelectorAll('.nav-link');

            let current = '';
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                const sectionHeight = section.clientHeight;
                if (window.pageYOffset >= (sectionTop - 200)) {
                    current = section.getAttribute('id');
                }
            });

            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        });
    </script>
</body>

</html>